{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cce4c29-d2b9-44f0-a327-f48b79867a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install torch torch-geometric networkx pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf7d8fe0-c954-4c16-ad95-49e9c75ed419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.image as mpimg\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "684cf59c-4e43-4aeb-9e94-7ad7a1f6ddfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_data = pd.read_csv('cleaned_user_data.csv')\n",
    "destination_data = pd.read_csv('cleaned_destination_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0b4851-f341-4959-b775-567e22d74eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode user IDs and destination names into node indices\n",
    "user_encoder = LabelEncoder()\n",
    "dest_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bd7b619-55b9-4379-b3bc-c31b5d83c82c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_indices = user_encoder.fit_transform(user_data['User ID'])\n",
    "dest_indices = dest_encoder.fit_transform(destination_data['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c45334-a0f9-4f71-b0f8-dfbd8a3beddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an edge list: each row is a (user_index, destination_index) pair\n",
    "edge_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9476b85-e0f8-4369-83e0-962ffea7757c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, row in user_data.iterrows():\n",
    "    # Ensure 'Bucket list destinations mapped' contains integers\n",
    "    bucket_list = row['Bucket list destinations mapped']\n",
    "    \n",
    "    if isinstance(bucket_list, str):\n",
    "        bucket_list = eval(bucket_list)  # Convert string representation of list back to list\n",
    "    \n",
    "    for dest_idx in bucket_list:\n",
    "        if pd.notna(dest_idx):\n",
    "            try:\n",
    "                # Ensure dest_idx is an integer\n",
    "                dest_idx = int(dest_idx)\n",
    "                edge_list.append([user_indices[idx], len(user_indices) + dest_idx])\n",
    "            except ValueError:\n",
    "                print(f\"Skipping invalid destination index: {dest_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48da3713-7ad2-4f2d-91f0-b6fe4dc100e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert edge list to tensor\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e92fe8bd-4579-44ac-b51c-4acad8d8ac12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare node features (optional, could be user or destination embeddings)\n",
    "num_users = len(user_indices)\n",
    "num_destinations = len(dest_indices)\n",
    "num_nodes = num_users + num_destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93e33d72-96d2-4d5d-bf49-56b3057d9a32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create node features (e.g., use some feature vectors for users and destinations)\n",
    "x = torch.eye(num_nodes)  # Identity matrix as a placeholder for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f1bc21-324d-4a1e-901c-b61ee99506fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a PyG data object\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a409be05-7dcc-47d1-96f7-b2defaf127ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCNRecommendation(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNRecommendation, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # First graph convolution layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Second graph convolution layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48d65d48-4f2d-43a6-b05a-06779cf00bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "model = GCNRecommendation(in_channels=data.num_node_features, hidden_channels=64, out_channels=32)\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d84778f9-f41e-4e91-9888-062005270283",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6881556510925293\n",
      "Epoch 1, Loss: 0.6851226091384888\n",
      "Epoch 2, Loss: 0.6807478666305542\n",
      "Epoch 3, Loss: 0.67481929063797\n",
      "Epoch 4, Loss: 0.6669038534164429\n",
      "Epoch 5, Loss: 0.6572286486625671\n",
      "Epoch 6, Loss: 0.6455220580101013\n",
      "Epoch 7, Loss: 0.6318177580833435\n",
      "Epoch 8, Loss: 0.6168252229690552\n",
      "Epoch 9, Loss: 0.6011227369308472\n",
      "Epoch 10, Loss: 0.5862175226211548\n",
      "Epoch 11, Loss: 0.5747014880180359\n",
      "Epoch 12, Loss: 0.56910640001297\n",
      "Epoch 13, Loss: 0.56834477186203\n",
      "Epoch 14, Loss: 0.5710943341255188\n",
      "Epoch 15, Loss: 0.5772814154624939\n",
      "Epoch 16, Loss: 0.5778958797454834\n",
      "Epoch 17, Loss: 0.5776435732841492\n",
      "Epoch 18, Loss: 0.5742995738983154\n",
      "Epoch 19, Loss: 0.5702221989631653\n",
      "Epoch 20, Loss: 0.5655210614204407\n",
      "Epoch 21, Loss: 0.5649187564849854\n",
      "Epoch 22, Loss: 0.5627686977386475\n",
      "Epoch 23, Loss: 0.5634481906890869\n",
      "Epoch 24, Loss: 0.5631458163261414\n",
      "Epoch 25, Loss: 0.5640755891799927\n",
      "Epoch 26, Loss: 0.565493106842041\n",
      "Epoch 27, Loss: 0.5667837858200073\n",
      "Epoch 28, Loss: 0.5666300654411316\n",
      "Epoch 29, Loss: 0.5655412673950195\n",
      "Epoch 30, Loss: 0.5648037791252136\n",
      "Epoch 31, Loss: 0.5632860064506531\n",
      "Epoch 32, Loss: 0.563209056854248\n",
      "Epoch 33, Loss: 0.559838593006134\n",
      "Epoch 34, Loss: 0.5599374175071716\n",
      "Epoch 35, Loss: 0.5593334436416626\n",
      "Epoch 36, Loss: 0.5576016306877136\n",
      "Epoch 37, Loss: 0.5576093792915344\n",
      "Epoch 38, Loss: 0.5610052943229675\n",
      "Epoch 39, Loss: 0.5593649744987488\n",
      "Epoch 40, Loss: 0.5608736276626587\n",
      "Epoch 41, Loss: 0.5613008141517639\n",
      "Epoch 42, Loss: 0.559834897518158\n",
      "Epoch 43, Loss: 0.560684859752655\n",
      "Epoch 44, Loss: 0.558046817779541\n",
      "Epoch 45, Loss: 0.5568894147872925\n",
      "Epoch 46, Loss: 0.5574161410331726\n",
      "Epoch 47, Loss: 0.5577298402786255\n",
      "Epoch 48, Loss: 0.558474063873291\n",
      "Epoch 49, Loss: 0.5573760271072388\n",
      "Epoch 50, Loss: 0.5592265725135803\n",
      "Epoch 51, Loss: 0.5573508143424988\n",
      "Epoch 52, Loss: 0.5580130219459534\n",
      "Epoch 53, Loss: 0.5589073300361633\n",
      "Epoch 54, Loss: 0.5541110038757324\n",
      "Epoch 55, Loss: 0.5568454265594482\n",
      "Epoch 56, Loss: 0.5567236542701721\n",
      "Epoch 57, Loss: 0.5589439272880554\n",
      "Epoch 58, Loss: 0.5543918013572693\n",
      "Epoch 59, Loss: 0.5552546381950378\n",
      "Epoch 60, Loss: 0.55717533826828\n",
      "Epoch 61, Loss: 0.5556524991989136\n",
      "Epoch 62, Loss: 0.5560094714164734\n",
      "Epoch 63, Loss: 0.556216299533844\n",
      "Epoch 64, Loss: 0.5548127889633179\n",
      "Epoch 65, Loss: 0.5553891658782959\n",
      "Epoch 66, Loss: 0.5553988218307495\n",
      "Epoch 67, Loss: 0.5554612278938293\n",
      "Epoch 68, Loss: 0.5570409297943115\n",
      "Epoch 69, Loss: 0.5548673272132874\n",
      "Epoch 70, Loss: 0.5542923212051392\n",
      "Epoch 71, Loss: 0.5537800788879395\n",
      "Epoch 72, Loss: 0.5544096827507019\n",
      "Epoch 73, Loss: 0.5547775626182556\n",
      "Epoch 74, Loss: 0.5530781149864197\n",
      "Epoch 75, Loss: 0.5526556968688965\n",
      "Epoch 76, Loss: 0.5532422065734863\n",
      "Epoch 77, Loss: 0.5518624782562256\n",
      "Epoch 78, Loss: 0.5507262349128723\n",
      "Epoch 79, Loss: 0.5516588091850281\n",
      "Epoch 80, Loss: 0.5497939586639404\n",
      "Epoch 81, Loss: 0.5519892573356628\n",
      "Epoch 82, Loss: 0.5500926375389099\n",
      "Epoch 83, Loss: 0.550146758556366\n",
      "Epoch 84, Loss: 0.5509817600250244\n",
      "Epoch 85, Loss: 0.5489342212677002\n",
      "Epoch 86, Loss: 0.5481152534484863\n",
      "Epoch 87, Loss: 0.5470137596130371\n",
      "Epoch 88, Loss: 0.5467882752418518\n",
      "Epoch 89, Loss: 0.5453142523765564\n",
      "Epoch 90, Loss: 0.5456922054290771\n",
      "Epoch 91, Loss: 0.5449324250221252\n",
      "Epoch 92, Loss: 0.5447853803634644\n",
      "Epoch 93, Loss: 0.5429521203041077\n",
      "Epoch 94, Loss: 0.5443536043167114\n",
      "Epoch 95, Loss: 0.5415294170379639\n",
      "Epoch 96, Loss: 0.5421790480613708\n",
      "Epoch 97, Loss: 0.5435971617698669\n",
      "Epoch 98, Loss: 0.5396490097045898\n",
      "Epoch 99, Loss: 0.5390455722808838\n",
      "Epoch 100, Loss: 0.5391622185707092\n",
      "Epoch 101, Loss: 0.5391981601715088\n",
      "Epoch 102, Loss: 0.5347387790679932\n",
      "Epoch 103, Loss: 0.5352219939231873\n",
      "Epoch 104, Loss: 0.5348649024963379\n",
      "Epoch 105, Loss: 0.5321140885353088\n",
      "Epoch 106, Loss: 0.5345499515533447\n",
      "Epoch 107, Loss: 0.5329432487487793\n",
      "Epoch 108, Loss: 0.5325808525085449\n",
      "Epoch 109, Loss: 0.527131974697113\n",
      "Epoch 110, Loss: 0.5289188027381897\n",
      "Epoch 111, Loss: 0.5293340682983398\n",
      "Epoch 112, Loss: 0.5269594788551331\n",
      "Epoch 113, Loss: 0.5262201428413391\n",
      "Epoch 114, Loss: 0.5237217545509338\n",
      "Epoch 115, Loss: 0.5238714814186096\n",
      "Epoch 116, Loss: 0.5213536024093628\n",
      "Epoch 117, Loss: 0.5188656449317932\n",
      "Epoch 118, Loss: 0.518094003200531\n",
      "Epoch 119, Loss: 0.516750693321228\n",
      "Epoch 120, Loss: 0.5159672498703003\n",
      "Epoch 121, Loss: 0.5155884027481079\n",
      "Epoch 122, Loss: 0.5165424942970276\n",
      "Epoch 123, Loss: 0.5133044719696045\n",
      "Epoch 124, Loss: 0.5113656520843506\n",
      "Epoch 125, Loss: 0.510614275932312\n",
      "Epoch 126, Loss: 0.5091341733932495\n",
      "Epoch 127, Loss: 0.5077590346336365\n",
      "Epoch 128, Loss: 0.5058043599128723\n",
      "Epoch 129, Loss: 0.5045415759086609\n",
      "Epoch 130, Loss: 0.5018661618232727\n",
      "Epoch 131, Loss: 0.5007704496383667\n",
      "Epoch 132, Loss: 0.5007026791572571\n",
      "Epoch 133, Loss: 0.4997949004173279\n",
      "Epoch 134, Loss: 0.4953165054321289\n",
      "Epoch 135, Loss: 0.49443182349205017\n",
      "Epoch 136, Loss: 0.49034687876701355\n",
      "Epoch 137, Loss: 0.4898512661457062\n",
      "Epoch 138, Loss: 0.48843348026275635\n",
      "Epoch 139, Loss: 0.4856433868408203\n",
      "Epoch 140, Loss: 0.48449936509132385\n",
      "Epoch 141, Loss: 0.4842802882194519\n",
      "Epoch 142, Loss: 0.4801144301891327\n",
      "Epoch 143, Loss: 0.4778721034526825\n",
      "Epoch 144, Loss: 0.4766835868358612\n",
      "Epoch 145, Loss: 0.4748079776763916\n",
      "Epoch 146, Loss: 0.4731360971927643\n",
      "Epoch 147, Loss: 0.46917614340782166\n",
      "Epoch 148, Loss: 0.4661291241645813\n",
      "Epoch 149, Loss: 0.46508392691612244\n",
      "Epoch 150, Loss: 0.46262025833129883\n",
      "Epoch 151, Loss: 0.461127907037735\n",
      "Epoch 152, Loss: 0.45733723044395447\n",
      "Epoch 153, Loss: 0.4562525153160095\n",
      "Epoch 154, Loss: 0.45075103640556335\n",
      "Epoch 155, Loss: 0.45332884788513184\n",
      "Epoch 156, Loss: 0.44668781757354736\n",
      "Epoch 157, Loss: 0.444426566362381\n",
      "Epoch 158, Loss: 0.4420841932296753\n",
      "Epoch 159, Loss: 0.4385678768157959\n",
      "Epoch 160, Loss: 0.43720534443855286\n",
      "Epoch 161, Loss: 0.4351928234100342\n",
      "Epoch 162, Loss: 0.4330126643180847\n",
      "Epoch 163, Loss: 0.4309493601322174\n",
      "Epoch 164, Loss: 0.4254074990749359\n",
      "Epoch 165, Loss: 0.42062821984291077\n",
      "Epoch 166, Loss: 0.4178895354270935\n",
      "Epoch 167, Loss: 0.4173872172832489\n",
      "Epoch 168, Loss: 0.41142943501472473\n",
      "Epoch 169, Loss: 0.40933889150619507\n",
      "Epoch 170, Loss: 0.4067443013191223\n",
      "Epoch 171, Loss: 0.4052758812904358\n",
      "Epoch 172, Loss: 0.4034997820854187\n",
      "Epoch 173, Loss: 0.39936941862106323\n",
      "Epoch 174, Loss: 0.3959117531776428\n",
      "Epoch 175, Loss: 0.3935352563858032\n",
      "Epoch 176, Loss: 0.38931968808174133\n",
      "Epoch 177, Loss: 0.3874344527721405\n",
      "Epoch 178, Loss: 0.3823860287666321\n",
      "Epoch 179, Loss: 0.38094744086265564\n",
      "Epoch 180, Loss: 0.37794017791748047\n",
      "Epoch 181, Loss: 0.3783907890319824\n",
      "Epoch 182, Loss: 0.371886670589447\n",
      "Epoch 183, Loss: 0.3707231283187866\n",
      "Epoch 184, Loss: 0.36711323261260986\n",
      "Epoch 185, Loss: 0.3636994957923889\n",
      "Epoch 186, Loss: 0.36136290431022644\n",
      "Epoch 187, Loss: 0.35687994956970215\n",
      "Epoch 188, Loss: 0.35538816452026367\n",
      "Epoch 189, Loss: 0.35369840264320374\n",
      "Epoch 190, Loss: 0.3536577522754669\n",
      "Epoch 191, Loss: 0.3491225838661194\n",
      "Epoch 192, Loss: 0.3469087779521942\n",
      "Epoch 193, Loss: 0.3427377939224243\n",
      "Epoch 194, Loss: 0.34212225675582886\n",
      "Epoch 195, Loss: 0.3376520872116089\n",
      "Epoch 196, Loss: 0.33971962332725525\n",
      "Epoch 197, Loss: 0.3361034691333771\n",
      "Epoch 198, Loss: 0.33246347308158875\n",
      "Epoch 199, Loss: 0.32920730113983154\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Number of negative samples per positive sample\n",
    "num_neg_samples = 1  # Can be tuned\n",
    "\n",
    "# Get the total number of nodes (users + destinations)\n",
    "num_total_nodes = data.num_nodes\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=5e-4)  # Reduced learning rate and added weight decay\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    \n",
    "    # Get user and destination node embeddings\n",
    "    user_embeddings = out[edge_index[0]]  # User nodes\n",
    "    dest_embeddings = out[edge_index[1]]  # Destination nodes\n",
    "    \n",
    "    # Compute interaction scores for positive edges\n",
    "    pos_interaction_scores = (user_embeddings * dest_embeddings).sum(dim=1)\n",
    "    pos_labels = torch.ones(edge_index.size(1))  # Positive labels\n",
    "    \n",
    "    # Generate negative samples (random user-destination pairs that do not exist in the graph)\n",
    "    neg_edge_list = []\n",
    "    for _ in range(num_neg_samples * edge_index.size(1)):\n",
    "        user_idx = random.randint(0, len(user_indices) - 1)  # Random user\n",
    "        dest_idx = random.randint(len(user_indices), num_total_nodes - 1)  # Random destination\n",
    "        neg_edge_list.append([user_idx, dest_idx])\n",
    "    \n",
    "    neg_edge_index = torch.tensor(neg_edge_list, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Get embeddings for negative samples\n",
    "    neg_user_embeddings = out[neg_edge_index[0]]\n",
    "    neg_dest_embeddings = out[neg_edge_index[1]]\n",
    "    \n",
    "    # Compute interaction scores for negative edges\n",
    "    neg_interaction_scores = (neg_user_embeddings * neg_dest_embeddings).sum(dim=1)\n",
    "    neg_labels = torch.zeros(neg_edge_index.size(1))  # Negative labels\n",
    "    \n",
    "    # Concatenate positive and negative scores and labels\n",
    "    all_interaction_scores = torch.cat([pos_interaction_scores, neg_interaction_scores])\n",
    "    all_labels = torch.cat([pos_labels, neg_labels])\n",
    "    \n",
    "    # Compute the loss using BCEWithLogitsLoss\n",
    "    loss = criterion(all_interaction_scores, all_labels)\n",
    "    \n",
    "    # Backpropagate and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51b97637-1b31-4ac2-b1b2-eda705a52266",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top k recommended destinations for each user: tensor([[10, 92, 61, 11, 76],\n",
      "        [10, 92, 61, 11, 76],\n",
      "        [10, 92, 61,  1, 76],\n",
      "        ...,\n",
      "        [10, 92, 61, 11, 76],\n",
      "        [10, 92, 61, 11, 76],\n",
      "        [10, 92, 61, 11, 76]])\n"
     ]
    }
   ],
   "source": [
    "# Get embeddings for all users and destinations after training\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model(data)\n",
    "\n",
    "user_embeddings = embeddings[:num_users]  # First part of the embedding matrix for users\n",
    "dest_embeddings = embeddings[num_users:]  # Second part for destinations\n",
    "\n",
    "# Compute similarity scores (dot product or cosine similarity) between users and destinations\n",
    "recommendation_scores = torch.matmul(user_embeddings, dest_embeddings.t())\n",
    "\n",
    "# Get top-k recommendations for each user\n",
    "k = 5\n",
    "top_k_recommendations = recommendation_scores.topk(k, dim=1).indices\n",
    "print(\"Top k recommended destinations for each user:\", top_k_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb460df-abd1-4f1f-8adf-3946248a582f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming top_k_recommendations is the tensor of top-k recommended destination indices\n",
    "# Also assuming 'dest_encoder' was already used to encode the destination names earlier\n",
    "\n",
    "# Convert tensor to a list of indices\n",
    "top_k_recommendations = top_k_recommendations.tolist()\n",
    "\n",
    "# Convert the destination indices back to the destination names\n",
    "recommendation_names = []\n",
    "for user_recommendations in top_k_recommendations:\n",
    "    # Convert each list of destination indices to names\n",
    "    decoded_dest_names = dest_encoder.inverse_transform(user_recommendations)\n",
    "    recommendation_names.append(decoded_dest_names)\n",
    "\n",
    "# Convert to DataFrame for better readability (Optional)\n",
    "recommended_df = pd.DataFrame(recommendation_names, columns=[f'Top {i+1} Destination' for i in range(len(recommendation_names[0]))])\n",
    "\n",
    "# Add user identifier (Optional if you want to associate with user IDs)\n",
    "recommended_df.insert(0, 'User ID', user_data['User ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23c16812-d615-4d1f-87ef-70a66e1816a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      User ID Top 1 Destination     Top 2 Destination Top 3 Destination  \\\n",
      "0           1       Ambalangoda  Elephant Point Beach   Council Chamber   \n",
      "1           2       Ambalangoda  Elephant Point Beach   Council Chamber   \n",
      "2           3       Ambalangoda  Elephant Point Beach   Council Chamber   \n",
      "3           4       Ambalangoda  Elephant Point Beach   Council Chamber   \n",
      "4           5       Ambalangoda  Elephant Point Beach   Council Chamber   \n",
      "...       ...               ...                   ...               ...   \n",
      "9995     9996   Aanda Ella Fall  Elephant Point Beach   Council Chamber   \n",
      "9996     9997       Ambalangoda  Elephant Point Beach   Council Chamber   \n",
      "9997     9998       Ambalangoda  Elephant Point Beach   Council Chamber   \n",
      "9998     9999       Ambalangoda  Elephant Point Beach   Council Chamber   \n",
      "9999    10000       Ambalangoda  Elephant Point Beach   Council Chamber   \n",
      "\n",
      "                    Top 4 Destination  \\\n",
      "0     Ambuluwawa Biodiversity Complex   \n",
      "1     Ambuluwawa Biodiversity Complex   \n",
      "2                     Aanda Ella Fall   \n",
      "3                Dimbulana hills Spot   \n",
      "4     Ambuluwawa Biodiversity Complex   \n",
      "...                               ...   \n",
      "9995                      Ambalangoda   \n",
      "9996  Ambuluwawa Biodiversity Complex   \n",
      "9997  Ambuluwawa Biodiversity Complex   \n",
      "9998  Ambuluwawa Biodiversity Complex   \n",
      "9999  Ambuluwawa Biodiversity Complex   \n",
      "\n",
      "                                 Top 5 Destination  \n",
      "0                             Dimbulana hills Spot  \n",
      "1                             Dimbulana hills Spot  \n",
      "2                             Dimbulana hills Spot  \n",
      "3                  Ambuluwawa Biodiversity Complex  \n",
      "4                             Dimbulana hills Spot  \n",
      "...                                            ...  \n",
      "9995  All Saints' Church, Galle - Church of Ceylon  \n",
      "9996                          Dimbulana hills Spot  \n",
      "9997                          Dimbulana hills Spot  \n",
      "9998                          Dimbulana hills Spot  \n",
      "9999                          Dimbulana hills Spot  \n",
      "\n",
      "[10000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the DataFrame of recommendations\n",
    "print(recommended_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e910678a-6116-4959-83b2-0810ae6b862a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recommended_df.to_csv(\"recommendations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4b04b-7851-482d-807f-fac8d4b7d1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
